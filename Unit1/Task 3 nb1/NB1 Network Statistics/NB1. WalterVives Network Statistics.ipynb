{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB1. Network Statistics\n",
    "\n",
    "Consider the following networks:\n",
    "\n",
    "* **Facebook Northwester University**(socfb-Northwestern25.edges.gz). Network of Facebook users at Northwestern University. Nodes represent people, and links stand for Facebook friend connections.\n",
    "* **US air transportation** (openflights_usa.edges.gz). The US air transportation network using flight data from OpenFlights.org. Nodes represent airports, and links stand for connections between them.\n",
    "* **Twitter USA Politics**(retweet-digraph.edges.gz). Retweet directed network with weigtht on Twitter, among people sharing posts about US politics. Links represent retweets of posts that used different hashtags (#tcot, #p2). The direction of the link from user A to B indicates that a message has propagated from A to B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "Create a table including the following characteristics for each network:\n",
    "* Number of Nodes $N$.\n",
    "* Number of Links $L$.\n",
    "* Density $d$.\n",
    "* Average Degree $\\langle k\\rangle $. \n",
    "* Clustering Coefficient $C_C$. \n",
    "    \n",
    "Consider the following observations:\n",
    "* In the case of undirected networks, compute the average in-degree.\n",
    "* In the case of undirected networks, compute the clustering coefficient without taking into account the directions of the edges. In NetworkX it is possible to use the ``` G.to_undirected() ``` method to return an undirected copy of a graph G.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files\n",
    "facebook = \"Networks/socfb-Northwestern25.edgelist\"\n",
    "US = \"Networks/openflights_usa.edges\" \n",
    "twitter = \"Networks/retweet-digraph.edges\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facebook Northwester University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes_fb: 10567\n",
      "edges_fb: 488337\n",
      "density_fb: 0.008747567709293077\n",
      "averageDegree_fb: 92.42680041639065\n",
      "averageClustering: 0.2379913948280604\n"
     ]
    }
   ],
   "source": [
    "G_fb = nx.read_edgelist(facebook, create_using = nx.Graph(), nodetype = int)\n",
    "\n",
    "# Nodes fb\n",
    "nodes_fb = G_fb.number_of_nodes()\n",
    "print(\"nodes_fb: {}\".format(nodes_fb))\n",
    "\n",
    "# Number of edges fb\n",
    "edges_fb = G_fb.number_of_edges()\n",
    "print(\"edges_fb: {}\".format(edges_fb))\n",
    "\n",
    "# Density fb\n",
    "density_fb = nx.density(G_fb)\n",
    "print(\"density_fb: {}\".format(density_fb))\n",
    "\n",
    "# Average Degree fb\n",
    "averageDegree_fb = (edges_fb * 2)/(nodes_fb)\n",
    "print(\"averageDegree_fb: {}\".format(averageDegree_fb))\n",
    "\n",
    "# Average Clustering Coefficient fb\n",
    "averageClustering_fb = nx.average_clustering(G_fb)\n",
    "print(\"averageClustering: {}\".format(averageClustering_fb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## US air transportation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes_us: 546\n",
      "edges_us: 2781\n",
      "density_us: 0.009345700171388244\n",
      "averageDegree_us: 5.093406593406593\n",
      "averageClustering_us: 0.4930453868822472\n"
     ]
    }
   ],
   "source": [
    "G_us = nx.read_edgelist(US, create_using = nx.DiGraph(), nodetype = str)\n",
    "\n",
    "# Nodes US\n",
    "nodes_us = G_us.number_of_nodes()\n",
    "print(\"nodes_us: {}\".format(nodes_us))\n",
    "\n",
    "# Number of edges US\n",
    "edges_us = G_us.number_of_edges()\n",
    "print(\"edges_us: {}\".format(edges_us))\n",
    "\n",
    "# Density US\n",
    "density_us = nx.density(G_us)\n",
    "print(\"density_us: {}\".format(density_us))\n",
    "\n",
    "# Average Degree US\n",
    "averageDegree_us = (edges_us)/(nodes_us)\n",
    "print(\"averageDegree_us: {}\".format(averageDegree_us))\n",
    "\n",
    "# Average Clustering Coefficient US\n",
    "G_US_undirected = G_us.to_undirected()\n",
    "averageClustering_us = nx.average_clustering(G_US_undirected)\n",
    "print(\"averageClustering_us: {}\".format(averageClustering_us))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter USA Politics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes_twitter: 18470\n",
      "edges_twitter: 48365\n",
      "density_twitter: 0.0001417819402846069\n",
      "averageDegree_twitter: 2.618570655116405\n",
      "averageClustering_twitter: 0.026152964008515068\n"
     ]
    }
   ],
   "source": [
    "G_twitter = nx.read_weighted_edgelist(twitter, create_using = nx.DiGraph(), nodetype = str)\n",
    "nodes_twitter = G_twitter.number_of_nodes()\n",
    "\n",
    "# Nodes twitter\n",
    "print(\"nodes_twitter: {}\".format(nodes_twitter))\n",
    "\n",
    "# Number of edges twitter\n",
    "edges_twitter = G_twitter.number_of_edges()\n",
    "print(\"edges_twitter: {}\".format(edges_twitter))\n",
    "\n",
    "# Density twitter\n",
    "density_twitter = nx.density(G_twitter)\n",
    "print(\"density_twitter: {}\".format(density_twitter))\n",
    "\n",
    "# Average Degree twitter\n",
    "averageDegree_twitter = (edges_twitter)/(nodes_twitter)\n",
    "print(\"averageDegree_twitter: {}\".format(averageDegree_twitter))\n",
    "\n",
    "# Average Clustering Coefficient twitter\n",
    "G_twitter_undirected = G_twitter.to_undirected()\n",
    "averageClustering_twitter = nx.average_clustering(G_twitter_undirected)\n",
    "print(\"averageClustering_twitter: {}\".format(averageClustering_twitter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Facebook Northwester University</th>\n",
       "      <th>US air transportation</th>\n",
       "      <th>Twitter USA Politics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Number of Nodes</th>\n",
       "      <td>10567.000000</td>\n",
       "      <td>546.000000</td>\n",
       "      <td>18470.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of Links</th>\n",
       "      <td>488337.000000</td>\n",
       "      <td>2781.000000</td>\n",
       "      <td>48365.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Density</th>\n",
       "      <td>0.008748</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Degree</th>\n",
       "      <td>92.426800</td>\n",
       "      <td>5.093407</td>\n",
       "      <td>2.618571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clustering Coefficient</th>\n",
       "      <td>0.237991</td>\n",
       "      <td>0.493045</td>\n",
       "      <td>0.026153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Facebook Northwester University  \\\n",
       "Number of Nodes                            10567.000000   \n",
       "Number of Links                           488337.000000   \n",
       "Density                                        0.008748   \n",
       "Average Degree                                92.426800   \n",
       "Clustering Coefficient                         0.237991   \n",
       "\n",
       "                        US air transportation  Twitter USA Politics  \n",
       "Number of Nodes                    546.000000          18470.000000  \n",
       "Number of Links                   2781.000000          48365.000000  \n",
       "Density                              0.009346              0.000142  \n",
       "Average Degree                       5.093407              2.618571  \n",
       "Clustering Coefficient               0.493045              0.026153  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data\n",
    "facebook = [int(nodes_fb), int(edges_fb), density_fb, averageDegree_fb, averageClustering_fb] \n",
    "us = [int(nodes_us), int(edges_us), density_us, averageDegree_us, averageClustering_us]\n",
    "twitter = [int(nodes_twitter), int(edges_twitter), density_twitter, averageDegree_twitter, averageClustering_twitter]\n",
    "\n",
    "data = [facebook, us, twitter]\n",
    "\n",
    "# Columns\n",
    "columns = [\"Number of Nodes\", \"Number of Links\", \n",
    "           \"Density\", \"Average Degree\",\n",
    "           \"Clustering Coefficient\"]\n",
    "\n",
    "# Index\n",
    "index = [\"Facebook Northwester University\", \"US air transportation\", \"Twitter USA Politics\"]\n",
    "\n",
    "table = pd.DataFrame(data = data, columns = columns, index = index).T\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average shortest-path length is a common aggregate distance measure for Networks. It can be obtained by averaging the shortest-path lengths across all pairs of nodes. The definition of this distance-based measure assume that the shortest-path length is defined for each pair of nodes. If there is any pairs without a path, then the the average path length is not defined. One way to present this result is by measuring only on the giant component; for the directed network it is possible to consider directed paths in the giants strongly connected component. However, due to the number of possible pairs of nodes, the computing of the average shortest-path length can be computational extensive.\n",
    "\n",
    "## Task 2\n",
    "Create a function ``` average_path_length_sample(G, N_sample)``` to compute the average path length on a Network. The function must identify if the network is directed or not.  The following method can be useful: ``` G.is_directed()```. In the case of directed networks it should use the strongly connected component to compute it. On the other hand, if the network is undirected, it should use the giang connected component of the network. \n",
    "\n",
    "In order to compute the average path length on a sample. Make a sample of ```N_sample``` randomly chosen nodes on the connected component and compute the average path length using it.\n",
    "\n",
    "The function must input ```G```a Network and ```N_sample```the number of nodes to be considered in the sample and output the average path length.\n",
    "\n",
    "Compute the average path length of the three given networks and add them into the table using ```N_sample=1000```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_path_length_sample(G, N_sample):\n",
    "    if G.is_directed() == True:\n",
    "        \n",
    "        # Max Strongly Connected Component\n",
    "        max_connected =  max(nx.strongly_connected_components(G), key=len)\n",
    "        strongly_subgraph = G.subgraph(max_connected)\n",
    "        \n",
    "        if (N_sample) > len(list(strongly_subgraph)):\n",
    "            raise NameError(\"The sample is greater than the total nodes\")\n",
    "\n",
    "        # Sample of N nodes in the Max Strongly Connected Component\n",
    "        sampled_nodes = random.sample(strongly_subgraph.nodes, N_sample)\n",
    "        sampled_graph = strongly_subgraph.subgraph(sampled_nodes)\n",
    "\n",
    "        # Shortest Path Length of each Node\n",
    "        shortest_path_length = dict(nx.shortest_path_length(sampled_graph))\n",
    "        \n",
    "        # Average Shortest Path Length\n",
    "        average_shortest_path_length = sum([(sum(x.values()))/(len(x)) for _, x in shortest_path_length.items()])/N_sample\n",
    "        \n",
    "        return average_shortest_path_length\n",
    "    \n",
    "                            \n",
    "    if G.is_directed() == False:\n",
    "\n",
    "        # Giant Component\n",
    "        max_connected = max(nx.connected_components(G), key=len)\n",
    "        giant_subgraph = G.subgraph(max_connected)\n",
    "        \n",
    "        if N_sample > len(list(giant_subgraph)):\n",
    "            raise NameError(\"The sample is greater than the total nodes\")\n",
    "        \n",
    "         # Sample of N nodes in the Giant Connected Component\n",
    "        sampled_nodes = random.sample(giant_subgraph.nodes, N_sample)\n",
    "        sampled_graph = giant_subgraph.subgraph(sampled_nodes)\n",
    "\n",
    "        # Shortest Path Length of each Node\n",
    "        shortest_path_length = dict(nx.shortest_path_length(sampled_graph))\n",
    "        \n",
    "        # Average Shortest Path Length\n",
    "        average_shortest_path_length = sum([(sum(x.values()))/(len(x)) for _, x in shortest_path_length.items()])/N_sample\n",
    "        \n",
    "        return average_shortest_path_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.734859682965527"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average Shortest Path Length Twitter\n",
    "average_Twitter = average_path_length_sample(G_twitter, 1000)\n",
    "average_Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.591450406910184"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average Shortest Path Length Facebook\n",
    "average_FB = average_path_length_sample(G_twitter, 1000)\n",
    "average_FB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average Shortest Path Length US Air\n",
    "average_US = average_path_length_sample(G_us, 1)\n",
    "average_US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfb =      Indirected  strongly connected connected component\\nUS air =  Directed     giant component\\nTwitter = Directed     giant component\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "fb =      Indirected  strongly connected connected component\n",
    "US air =  Directed     giant component\n",
    "Twitter = Directed     giant component\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Twitter USA Politics</th>\n",
       "      <th>Facebook Northwester University</th>\n",
       "      <th>US air transportation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Average Path Length Sample</th>\n",
       "      <td>4.73486</td>\n",
       "      <td>4.59145</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No. nodes</th>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Twitter USA Politics  \\\n",
       "Average Path Length Sample               4.73486   \n",
       "No. nodes                             1000.00000   \n",
       "\n",
       "                            Facebook Northwester University  \\\n",
       "Average Path Length Sample                          4.59145   \n",
       "No. nodes                                        1000.00000   \n",
       "\n",
       "                            US air transportation  \n",
       "Average Path Length Sample                    0.0  \n",
       "No. nodes                                     1.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw = [average_Twitter, 1000]\n",
    "fb = [average_FB, 1000]\n",
    "us_air = [average_US, 1]\n",
    "data = [tw, fb, us_air]\n",
    "columns = [\"Average Path Length Sample\", \"No. nodes\"]\n",
    "index = [\"Twitter USA Politics\", \"Facebook Northwester University\", \"US air transportation\"]\n",
    "\n",
    "\n",
    "\n",
    "table2 = pd.DataFrame(data = data,\n",
    "                      columns = columns,\n",
    "                      index = index)\n",
    "table2.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prueba = {'n9059':   {'n9059': 0,\n",
    "                      'n6325': 1,\n",
    "                      'n17936': 1,\n",
    "                      'n16579': 1,\n",
    "                      'n7708': 1,\n",
    "                      'n17738': 1,\n",
    "                      'n9826': 1,\n",
    "                      'n7720': 1},\n",
    "          'n9012':   {'n9059': 0,\n",
    "                      'n6325': 1,\n",
    "                      'n17936': 2,\n",
    "                      'n16579': 3,\n",
    "                      'n7708': 34,\n",
    "                      'n17738': 23,\n",
    "                      'n9826': 32,\n",
    "                      'n7720': 16},\n",
    "          'n908':   {'n9059': 1,\n",
    "                      'n6325': 5,\n",
    "                      'n17936': 5,\n",
    "                      'n16579': 15,\n",
    "                      'n7708': 13,\n",
    "                      'n17738': 31,\n",
    "                      'n9826': 15,\n",
    "                      'n7720': 19}\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[dict_values([0, 1, 1, 1, 1, 1, 1, 1]),\n",
       " dict_values([0, 1, 2, 3, 34, 23, 32, 16]),\n",
       " dict_values([1, 5, 5, 15, 13, 31, 15, 19])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_values = []\n",
    "for _, x in prueba.items():\n",
    "    total_values.append(x.values())\n",
    "\n",
    "total_values    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.875, 13.875, 13.0]\n",
      "27.75\n"
     ]
    }
   ],
   "source": [
    "q = [(sum(i)/len(i)) for i in total_values]\n",
    "print(q)\n",
    "print(sum(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.875, 13.875, 13.0]\n",
      "27.75\n"
     ]
    }
   ],
   "source": [
    "w = [(sum(x.values()))/(len(x)) for y, x in prueba.items()]\n",
    "print(w)\n",
    "print(sum(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.75"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = sum([(sum(x.values()))/(len(x)) for y, x in prueba.items()])\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prueba average shortest path length: 9.25\n"
     ]
    }
   ],
   "source": [
    "w = sum([(sum(x.values()))/(len(x)) for _, x in prueba.items()])/3\n",
    "print(\"prueba average shortest path length: {}\".format(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful NetworkX Methods\n",
    "\n",
    "* [Reading and writing graphs](https://networkx.github.io/documentation/networkx-1.9/reference/readwrite.html). Check the ```read_edgelist``` method.\n",
    "* [Components](https://networkx.github.io/documentation/stable/reference/algorithms/component.html).\n",
    "\n",
    "## References\n",
    "[1] F. Mencszer, S. Fortunato, C. A. Davis (2020). A First Course in Network Science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
